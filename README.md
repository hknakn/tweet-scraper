# Twitter Scraper

A Python tool for scraping tweets from Twitter profiles. This tool uses Selenium to automate browser interactions and scrape tweets, including text content and engagement metrics (comments, retweets, likes, and views).

## Project Structure

```
twitter_scraper/
â”œâ”€â”€ src/                      # Source code package
â”‚   â”œâ”€â”€ browser/             # Browser management
â”‚   â”‚   â””â”€â”€ browser_manager.py
â”‚   â”œâ”€â”€ tweet/               # Tweet processing
â”‚   â”‚   â”œâ”€â”€ processor.py
â”‚   â”‚   â””â”€â”€ file_handler.py
â”‚   â”œâ”€â”€ config/              # Configuration
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â””â”€â”€ scraper.py           # Main scraper class
â”œâ”€â”€ scripts/                  # Command-line scripts
â”‚   â””â”€â”€ get_tweets.py        # Main script
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md               # Project documentation
â”œâ”€â”€ .env                    # Twitter credentials
â””â”€â”€ .env.template          # Template for .env file
```

## Features

- Scrapes tweets from any public Twitter profile
- Captures tweet text, timestamp, and engagement metrics
- Saves tweets immediately as they are found
- Handles rate limiting and scrolling automatically
- Supports headless mode for background operation
- Formats numbers in a human-readable way (e.g., 1.5K, 2.3M)
- Deduplicates tweets to avoid duplicates
- Provides progress bar and detailed logging

## Requirements

- Python 3.6+
- Chrome browser
- ChromeDriver (compatible with your Chrome version)

## Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/twitter_scraper.git
   cd twitter_scraper
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Create a `.env` file with your Twitter credentials:
   ```bash
   cp .env.template .env
   # Edit .env with your Twitter username and password
   ```

## Usage

Run the script:
```bash
python scripts/get_tweets.py
```

The script will:
1. Prompt for Twitter credentials if not found in `.env`
2. Ask for the username to scrape
3. Ask whether to run in headless mode
4. Start scraping tweets
5. Save tweets to a file with timestamp in the name

## Output Format

Tweets are saved in a text file with the following format:
```
ğŸ“± Tweets from @username
ğŸ’¾ Started scraping at YYYY-MM-DD HH:MM:SS
==========================================

ğŸ•’ January 01, 2024 at 12:34 PM

Tweet text goes here...

ğŸ’¬ 123 Comments  |  ğŸ”„ 45 Retweets  |  â¤ï¸ 6.7K Likes  |  ğŸ‘ï¸ 89.1K Views
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

## Contributing

Feel free to submit issues, fork the repository, and create pull requests for any improvements.

## License

This project is licensed under the MIT License - see the LICENSE file for details. 